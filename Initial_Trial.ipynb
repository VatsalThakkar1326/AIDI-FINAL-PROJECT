{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.2.73)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.17.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->ultralytics) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vatsa\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vatsa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_counter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ObjectCounter\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO, solutions\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics.solutions.object_counter import ObjectCounter\n",
    "\n",
    "from ultralytics import YOLO, solutions\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "line_points = [(20, 400), (1080, 400)]  # line or region points\n",
    "classes_to_count = [0]  # person and car classes for count\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init Object Counter\n",
    "counter = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points,\n",
    "    names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    ")\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    tracks = model.track(im0, persist=True, show=False, classes=classes_to_count)\n",
    "\n",
    "    im0 = counter.start_counting(im0, tracks)\n",
    "    video_writer.write(im0)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line Counter Initiated.\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nMeta: registered at /dev/null:440 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ..\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ..\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ..\\torch\\csrc\\autograd\\TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\nAutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\nFuncTorchBatched: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ..\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ..\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:158 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     video_writer\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m     28\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m---> 30\u001b[0m \u001b[43mcount_specific_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_specific_classes.avi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov8n.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mcount_specific_classes\u001b[1;34m(output_video_path, model_path, classes_to_count)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo frame is empty or video processing has been successfully completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m tracks \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_to_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m im0 \u001b[38;5;241m=\u001b[39m counter\u001b[38;5;241m.\u001b[39mstart_counting(im0, tracks)\n\u001b[0;32m     24\u001b[0m video_writer\u001b[38;5;241m.\u001b[39mwrite(im0)\n",
      "File \u001b[1;32mc:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\model.py:610\u001b[0m, in \u001b[0;36mModel.track\u001b[1;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[0;32m    608\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[0;32m    609\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\model.py:563\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\engine\\predictor.py:261\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim0s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_predict_postprocess_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Visualize, save, write results\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\predict.py:25\u001b[0m, in \u001b[0;36mDetectionPredictor.postprocess\u001b[1;34m(self, preds, img, orig_imgs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpostprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds, img, orig_imgs):\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Post-processes predictions and returns a list of Results objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnon_max_suppression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miou\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43magnostic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magnostic_nms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_det\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orig_imgs, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# input images are a torch.Tensor, not a list\u001b[39;00m\n\u001b[0;32m     35\u001b[0m         orig_imgs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_torch2numpy_batch(orig_imgs)\n",
      "File \u001b[1;32mc:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\utils\\ops.py:291\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[1;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m x[:, :\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m c  \u001b[38;5;66;03m# boxes (offset by class)\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_thres\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# NMS\u001b[39;00m\n\u001b[0;32m    292\u001b[0m i \u001b[38;5;241m=\u001b[39m i[:max_det]  \u001b[38;5;66;03m# limit detections\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;66;03m# # Experimental\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# merge = False  # use merge-NMS\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;66;03m# if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m#     if redundant:\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m#         i = i[iou.sum(1) > 1]  # require redundancy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\ops\\boxes.py:41\u001b[0m, in \u001b[0;36mnms\u001b[1;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[0;32m     39\u001b[0m     _log_api_usage_once(nms)\n\u001b[0;32m     40\u001b[0m _assert_has_ops()\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nMeta: registered at /dev/null:440 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ..\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ..\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ..\\torch\\csrc\\autograd\\TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\nAutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\nFuncTorchBatched: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ..\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ..\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:158 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO, solutions\n",
    "from ultralytics.solutions.object_counter import ObjectCounter\n",
    "\n",
    "def count_specific_classes(output_video_path, model_path, classes_to_count):\n",
    "    \"\"\"Count specific classes of objects in a video.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    cap = cv2.VideoCapture(0)  # Use 0 for webcam feed\n",
    "    assert cap.isOpened(), \"Error reading video feed\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    line_points = [(20, 400), (1080, 400)]\n",
    "    video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "    counter = solutions.ObjectCounter(\n",
    "        view_img=True, reg_pts=line_points, names=model.names, draw_tracks=True, line_thickness=2\n",
    "    )\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, im0 = cap.read()\n",
    "        if not success:\n",
    "            print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "            break\n",
    "        tracks = model.track(im0, persist=True, show=False, classes=classes_to_count)\n",
    "        im0 = counter.start_counting(im0, tracks)\n",
    "        video_writer.write(im0)\n",
    "\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "count_specific_classes(\"output_specific_classes.avi\", \"yolov8n.pt\", [0, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vatsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ultralytics\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "print(ultralytics.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.solutions.object_counter import ObjectCounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
